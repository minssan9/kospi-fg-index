import { performance } from 'perf_hooks'
import os from 'os'
import process from 'process'
import { PrismaClient } from '@prisma/client'
import { EventEmitter } from 'events'

const prisma = new PrismaClient()

// ============================================================================
// TYPES AND INTERFACES
// ============================================================================

export interface SystemMetrics {
  timestamp: Date
  cpu: CpuMetrics
  memory: MemoryMetrics
  database: DatabaseMetrics
  api: ApiMetrics
  business: BusinessMetrics
  gc: GcMetrics
}

export interface CpuMetrics {
  usage: number // percentage
  loadAverage: number[]
  cores: number
}

export interface MemoryMetrics {
  rss: number // bytes
  heapTotal: number // bytes
  heapUsed: number // bytes
  external: number // bytes
  arrayBuffers: number // bytes
  heapUtilization: number // percentage
  systemMemory: {
    total: number // bytes
    free: number // bytes
    used: number // bytes
    utilization: number // percentage
  }
}

export interface DatabaseMetrics {
  connectionPool: {
    active: number
    idle: number
    waiting: number
    max: number
    utilization: number // percentage
  }
  queryPerformance: {
    averageResponseTime: number // ms
    slowQueries: number
    errorRate: number // percentage
  }
  health: 'HEALTHY' | 'DEGRADED' | 'CRITICAL'
  responseTime: number // ms
}

export interface ApiMetrics {
  requestCount: number
  averageResponseTime: number // ms
  errorRate: number // percentage
  throughput: number // requests per second
  slowEndpoints: Array<{
    endpoint: string
    averageTime: number
    count: number
  }>
}

export interface BusinessMetrics {
  dataCollection: {
    successRate: number // percentage
    lastSuccessfulRun: Date | null
    failedRuns24h: number
    averageCollectionTime: number // ms
  }
  fearGreedCalculation: {
    calculationsToday: number
    averageCalculationTime: number // ms
    accuracy: number // percentage based on confidence scores
    lastCalculation: Date | null
  }
  systemHealth: {
    overallScore: number // 0-100
    criticalIssues: number
    warnings: number
  }
}

export interface GcMetrics {
  collections: {
    minor: number
    major: number
    total: number
  }
  gcTime: {
    total: number // ms
    average: number // ms
    percentage: number // percentage of uptime
  }
  heapGrowthRate: number // bytes per second
  memoryLeakIndicator: boolean
}

export interface Alert {
  id: string
  type: 'CRITICAL' | 'WARNING' | 'INFO'
  category: 'PERFORMANCE' | 'DATABASE' | 'API' | 'BUSINESS' | 'SYSTEM' | 'SECURITY'
  title: string
  message: string
  threshold: number
  actualValue: number
  timestamp: Date
  resolved: boolean
  resolvedAt?: Date
}

export interface MonitoringConfig {
  alertThresholds: {
    cpu: { warning: 70, critical: 85 }
    memory: { warning: 80, critical: 90 }
    database: { warning: 5000, critical: 10000 } // response time in ms
    errorRate: { warning: 5, critical: 10 } // percentage
    dataCollection: { warning: 90, critical: 80 } // success rate percentage
  }
  sampling: {
    interval: number // ms
    retention: number // hours
  }
  notifications: {
    enabled: boolean
    channels: string[]
  }
}

// ============================================================================
// MONITORING SERVICE CLASS
// ============================================================================

export class MonitoringService extends EventEmitter {
  private static instance: MonitoringService
  private metrics: SystemMetrics[] = []
  private alerts: Alert[] = []
  private config: MonitoringConfig
  private intervalId: NodeJS.Timeout | null = null
  private lastGcStats: any = null
  private requestStats = new Map<string, { times: number[], errors: number }>()
  
  constructor() {
    super()
    this.config = this.getDefaultConfig()
    this.initializeGcMonitoring()
  }

  static getInstance(): MonitoringService {
    if (!MonitoringService.instance) {
      MonitoringService.instance = new MonitoringService()
    }
    return MonitoringService.instance
  }

  // ============================================================================
  // CONFIGURATION
  // ============================================================================

  private getDefaultConfig(): MonitoringConfig {
    return {
      alertThresholds: {
        cpu: { warning: 70, critical: 85 },
        memory: { warning: 80, critical: 90 },
        database: { warning: 5000, critical: 10000 },
        errorRate: { warning: 5, critical: 10 },
        dataCollection: { warning: 90, critical: 80 }
      },
      sampling: {
        interval: 30000, // 30 seconds
        retention: 24 // 24 hours
      },
      notifications: {
        enabled: true,
        channels: ['console', 'database']
      }
    }
  }

  updateConfig(newConfig: Partial<MonitoringConfig>): void {
    this.config = { ...this.config, ...newConfig }
    this.emit('configUpdated', this.config)
  }

  // ============================================================================
  // PERFORMANCE METRICS COLLECTION
  // ============================================================================

  async collectSystemMetrics(): Promise<SystemMetrics> {
    const timestamp = new Date()
    
    const [cpu, memory, database, api, business, gc] = await Promise.all([
      this.collectCpuMetrics(),
      this.collectMemoryMetrics(),
      this.collectDatabaseMetrics(),
      this.collectApiMetrics(),
      this.collectBusinessMetrics(),
      this.collectGcMetrics()
    ])

    const metrics: SystemMetrics = {
      timestamp,
      cpu,
      memory,
      database,
      api,
      business,
      gc
    }

    // Store metrics
    this.addMetrics(metrics)
    
    // Check for alerts
    await this.checkAlerts(metrics)
    
    return metrics
  }

  private async collectCpuMetrics(): Promise<CpuMetrics> {
    const cpus = os.cpus()
    const loadAverage = os.loadavg()
    
    // Calculate CPU usage (simplified approach)
    const usage = Math.min(100, Math.max(0, loadAverage[0] / cpus.length * 100))
    
    return {
      usage: Math.round(usage * 100) / 100,
      loadAverage,
      cores: cpus.length
    }
  }

  private async collectMemoryMetrics(): Promise<MemoryMetrics> {
    const memUsage = process.memoryUsage()
    const totalMemory = os.totalmem()
    const freeMemory = os.freemem()
    const usedMemory = totalMemory - freeMemory
    
    return {
      rss: memUsage.rss,
      heapTotal: memUsage.heapTotal,
      heapUsed: memUsage.heapUsed,
      external: memUsage.external,
      arrayBuffers: memUsage.arrayBuffers,
      heapUtilization: Math.round((memUsage.heapUsed / memUsage.heapTotal) * 100 * 100) / 100,
      systemMemory: {
        total: totalMemory,
        free: freeMemory,
        used: usedMemory,
        utilization: Math.round((usedMemory / totalMemory) * 100 * 100) / 100
      }
    }
  }

  private async collectDatabaseMetrics(): Promise<DatabaseMetrics> {
    const startTime = performance.now()
    let health: 'HEALTHY' | 'DEGRADED' | 'CRITICAL' = 'HEALTHY'
    
    try {
      // Test database connection
      await prisma.fearGreedIndex.findFirst({
        orderBy: { date: 'desc' },
        take: 1
      })
      
      const responseTime = Math.round(performance.now() - startTime)
      
      // Mock connection pool data (Prisma doesn't expose this directly)
      const connectionPool = {
        active: Math.floor(Math.random() * 5) + 1,
        idle: Math.floor(Math.random() * 10) + 5,
        waiting: Math.floor(Math.random() * 3),
        max: 20,
        utilization: 0
      }
      connectionPool.utilization = Math.round(((connectionPool.active + connectionPool.waiting) / connectionPool.max) * 100)
      
      // Determine health based on response time
      if (responseTime > this.config.alertThresholds.database.critical) {
        health = 'CRITICAL'
      } else if (responseTime > this.config.alertThresholds.database.warning) {
        health = 'DEGRADED'
      }
      
      return {
        connectionPool,
        queryPerformance: {
          averageResponseTime: responseTime,
          slowQueries: Math.floor(Math.random() * 3),
          errorRate: Math.random() * 2 // Mock error rate
        },
        health,
        responseTime
      }
    } catch (error) {
      return {
        connectionPool: {
          active: 0,
          idle: 0,
          waiting: 0,
          max: 20,
          utilization: 0
        },
        queryPerformance: {
          averageResponseTime: -1,
          slowQueries: 0,
          errorRate: 100
        },
        health: 'CRITICAL',
        responseTime: Math.round(performance.now() - startTime)
      }
    }
  }

  private async collectApiMetrics(): Promise<ApiMetrics> {
    const now = Date.now()
    const oneMinuteAgo = now - 60000
    
    let totalRequests = 0
    let totalTime = 0
    let totalErrors = 0
    const slowEndpoints: Array<{ endpoint: string; averageTime: number; count: number }> = []
    
    for (const [endpoint, stats] of this.requestStats.entries()) {
      const recentTimes = stats.times.filter(time => time > oneMinuteAgo)
      if (recentTimes.length > 0) {
        totalRequests += recentTimes.length
        const avgTime = recentTimes.reduce((sum, time) => sum + time, 0) / recentTimes.length
        totalTime += avgTime * recentTimes.length
        totalErrors += stats.errors
        
        if (avgTime > 1000) { // Slow endpoints > 1 second
          slowEndpoints.push({
            endpoint,
            averageTime: Math.round(avgTime),
            count: recentTimes.length
          })
        }
      }
    }
    
    return {
      requestCount: totalRequests,
      averageResponseTime: totalRequests > 0 ? Math.round(totalTime / totalRequests) : 0,
      errorRate: totalRequests > 0 ? Math.round((totalErrors / totalRequests) * 100 * 100) / 100 : 0,
      throughput: Math.round(totalRequests / 60 * 100) / 100, // requests per second
      slowEndpoints: slowEndpoints.slice(0, 5) // Top 5 slow endpoints
    }
  }

  private async collectBusinessMetrics(): Promise<BusinessMetrics> {
    try {
      // Get data collection status from last 24 hours
      const oneDayAgo = new Date(Date.now() - 24 * 60 * 60 * 1000)
      const collectionLogs = await prisma.dataCollectionLog.findMany({
        where: {
          createdAt: { gte: oneDayAgo }
        },
        orderBy: { createdAt: 'desc' }
      })
      
      const successfulRuns = collectionLogs.filter(log => log.status === 'SUCCESS')
      const successRate = collectionLogs.length > 0 ? 
        Math.round((successfulRuns.length / collectionLogs.length) * 100 * 100) / 100 : 100
      
      const lastSuccessfulRun = successfulRuns.length > 0 ? successfulRuns[0].createdAt : null
      const failedRuns24h = collectionLogs.filter(log => log.status === 'FAILED').length
      const averageCollectionTime = collectionLogs.length > 0 ?
        Math.round(collectionLogs.reduce((sum, log) => sum + (log.duration || 0), 0) / collectionLogs.length) : 0
      
      // Get Fear & Greed calculation metrics
      const today = new Date()
      today.setHours(0, 0, 0, 0)
      const fearGreedToday = await prisma.fearGreedIndex.findMany({
        where: {
          createdAt: { gte: today }
        }
      })
      
      const calculationsToday = fearGreedToday.length
      const averageConfidence = fearGreedToday.length > 0 ?
        Math.round(fearGreedToday.reduce((sum, fg) => sum + fg.confidence, 0) / fearGreedToday.length) : 0
      
      const lastCalculation = await prisma.fearGreedIndex.findFirst({
        orderBy: { createdAt: 'desc' }
      })
      
      // Calculate overall system health score
      const overallScore = this.calculateOverallHealthScore(successRate, averageConfidence)
      const criticalIssues = this.alerts.filter(a => !a.resolved && a.type === 'CRITICAL').length
      const warnings = this.alerts.filter(a => !a.resolved && a.type === 'WARNING').length
      
      return {
        dataCollection: {
          successRate,
          lastSuccessfulRun,
          failedRuns24h,
          averageCollectionTime
        },
        fearGreedCalculation: {
          calculationsToday,
          averageCalculationTime: 150, // Mock value - would need to track this
          accuracy: averageConfidence,
          lastCalculation: lastCalculation?.createdAt || null
        },
        systemHealth: {
          overallScore,
          criticalIssues,
          warnings
        }
      }
    } catch (error) {
      console.error('[Monitoring] Error collecting business metrics:', error)
      return {
        dataCollection: {
          successRate: 0,
          lastSuccessfulRun: null,
          failedRuns24h: 0,
          averageCollectionTime: 0
        },
        fearGreedCalculation: {
          calculationsToday: 0,
          averageCalculationTime: 0,
          accuracy: 0,
          lastCalculation: null
        },
        systemHealth: {
          overallScore: 0,
          criticalIssues: 1,
          warnings: 0
        }
      }
    }
  }

  private initializeGcMonitoring(): void {
    if (process.versions.node) {
      try {
        // Try to enable GC monitoring if available
        if (typeof process.binding === 'function') {
          const v8 = require('v8')
          this.lastGcStats = v8.getHeapStatistics()
        }
      } catch (error) {
        console.warn('[Monitoring] GC monitoring not available:', error.message)
      }
    }
  }

  private async collectGcMetrics(): Promise<GcMetrics> {
    try {
      const v8 = require('v8')
      const heapStats = v8.getHeapStatistics()
      
      // Mock GC collection data (Node.js doesn't expose this easily without flags)
      const collections = {
        minor: Math.floor(Math.random() * 100) + 50,
        major: Math.floor(Math.random() * 10) + 5,
        total: 0
      }
      collections.total = collections.minor + collections.major
      
      const gcTime = {
        total: Math.floor(Math.random() * 1000) + 100, // ms
        average: 0,
        percentage: 0
      }
      gcTime.average = Math.round(gcTime.total / collections.total)
      gcTime.percentage = Math.round((gcTime.total / (process.uptime() * 1000)) * 100 * 100) / 100
      
      // Calculate heap growth rate
      const heapGrowthRate = this.lastGcStats ? 
        (heapStats.used_heap_size - this.lastGcStats.used_heap_size) / 30 : 0 // bytes per second (30s interval)
      
      // Memory leak detection (simplified)
      const memoryLeakIndicator = heapGrowthRate > 1024 * 1024 && // > 1MB/s growth
        heapStats.heap_size_limit - heapStats.used_heap_size < heapStats.heap_size_limit * 0.1 // < 10% free
      
      this.lastGcStats = heapStats
      
      return {
        collections,
        gcTime,
        heapGrowthRate: Math.round(heapGrowthRate),
        memoryLeakIndicator
      }
    } catch (error) {
      return {
        collections: { minor: 0, major: 0, total: 0 },
        gcTime: { total: 0, average: 0, percentage: 0 },
        heapGrowthRate: 0,
        memoryLeakIndicator: false
      }
    }
  }

  private calculateOverallHealthScore(dataSuccessRate: number, calculationAccuracy: number): number {
    const cpuScore = this.getLatestCpuScore()
    const memoryScore = this.getLatestMemoryScore()
    const databaseScore = this.getLatestDatabaseScore()
    
    // Weighted average: data collection (30%), calculation accuracy (25%), system metrics (45%)
    const score = (
      dataSuccessRate * 0.30 +
      calculationAccuracy * 0.25 +
      cpuScore * 0.15 +
      memoryScore * 0.15 +
      databaseScore * 0.15
    )
    
    return Math.round(Math.max(0, Math.min(100, score)))
  }

  private getLatestCpuScore(): number {
    const latest = this.getLatestMetrics()
    if (!latest) return 100
    return Math.max(0, 100 - latest.cpu.usage)
  }

  private getLatestMemoryScore(): number {
    const latest = this.getLatestMetrics()
    if (!latest) return 100
    return Math.max(0, 100 - latest.memory.systemMemory.utilization)
  }

  private getLatestDatabaseScore(): number {
    const latest = this.getLatestMetrics()
    if (!latest) return 100
    if (latest.database.health === 'CRITICAL') return 0
    if (latest.database.health === 'DEGRADED') return 50
    return 100
  }

  // ============================================================================
  // ALERT SYSTEM
  // ============================================================================

  private async checkAlerts(metrics: SystemMetrics): Promise<void> {
    const newAlerts: Alert[] = []
    
    // CPU alerts
    if (metrics.cpu.usage >= this.config.alertThresholds.cpu.critical) {
      newAlerts.push(this.createAlert(
        'CRITICAL', 'PERFORMANCE', 'High CPU Usage',
        `CPU usage is critically high: ${metrics.cpu.usage}%`,
        this.config.alertThresholds.cpu.critical,
        metrics.cpu.usage
      ))
    } else if (metrics.cpu.usage >= this.config.alertThresholds.cpu.warning) {
      newAlerts.push(this.createAlert(
        'WARNING', 'PERFORMANCE', 'Elevated CPU Usage',
        `CPU usage is elevated: ${metrics.cpu.usage}%`,
        this.config.alertThresholds.cpu.warning,
        metrics.cpu.usage
      ))
    }
    
    // Memory alerts
    if (metrics.memory.systemMemory.utilization >= this.config.alertThresholds.memory.critical) {
      newAlerts.push(this.createAlert(
        'CRITICAL', 'PERFORMANCE', 'High Memory Usage',
        `Memory usage is critically high: ${metrics.memory.systemMemory.utilization}%`,
        this.config.alertThresholds.memory.critical,
        metrics.memory.systemMemory.utilization
      ))
    } else if (metrics.memory.systemMemory.utilization >= this.config.alertThresholds.memory.warning) {
      newAlerts.push(this.createAlert(
        'WARNING', 'PERFORMANCE', 'Elevated Memory Usage',
        `Memory usage is elevated: ${metrics.memory.systemMemory.utilization}%`,
        this.config.alertThresholds.memory.warning,
        metrics.memory.systemMemory.utilization
      ))
    }
    
    // Database alerts
    if (metrics.database.health === 'CRITICAL') {
      newAlerts.push(this.createAlert(
        'CRITICAL', 'DATABASE', 'Database Connection Critical',
        `Database is in critical state with ${metrics.database.responseTime}ms response time`,
        this.config.alertThresholds.database.critical,
        metrics.database.responseTime
      ))
    } else if (metrics.database.health === 'DEGRADED') {
      newAlerts.push(this.createAlert(
        'WARNING', 'DATABASE', 'Database Performance Degraded',
        `Database response time is slow: ${metrics.database.responseTime}ms`,
        this.config.alertThresholds.database.warning,
        metrics.database.responseTime
      ))
    }
    
    // API error rate alerts
    if (metrics.api.errorRate >= this.config.alertThresholds.errorRate.critical) {
      newAlerts.push(this.createAlert(
        'CRITICAL', 'API', 'High API Error Rate',
        `API error rate is critically high: ${metrics.api.errorRate}%`,
        this.config.alertThresholds.errorRate.critical,
        metrics.api.errorRate
      ))
    } else if (metrics.api.errorRate >= this.config.alertThresholds.errorRate.warning) {
      newAlerts.push(this.createAlert(
        'WARNING', 'API', 'Elevated API Error Rate',
        `API error rate is elevated: ${metrics.api.errorRate}%`,
        this.config.alertThresholds.errorRate.warning,
        metrics.api.errorRate
      ))
    }
    
    // Data collection alerts
    if (metrics.business.dataCollection.successRate <= this.config.alertThresholds.dataCollection.critical) {
      newAlerts.push(this.createAlert(
        'CRITICAL', 'BUSINESS', 'Data Collection Failure',
        `Data collection success rate is critically low: ${metrics.business.dataCollection.successRate}%`,
        this.config.alertThresholds.dataCollection.critical,
        metrics.business.dataCollection.successRate
      ))
    } else if (metrics.business.dataCollection.successRate <= this.config.alertThresholds.dataCollection.warning) {
      newAlerts.push(this.createAlert(
        'WARNING', 'BUSINESS', 'Data Collection Issues',
        `Data collection success rate is low: ${metrics.business.dataCollection.successRate}%`,
        this.config.alertThresholds.dataCollection.warning,
        metrics.business.dataCollection.successRate
      ))
    }
    
    // Memory leak alerts
    if (metrics.gc.memoryLeakIndicator) {
      newAlerts.push(this.createAlert(
        'CRITICAL', 'SYSTEM', 'Memory Leak Detected',
        `Potential memory leak detected with heap growth rate: ${metrics.gc.heapGrowthRate} bytes/sec`,
        0,
        metrics.gc.heapGrowthRate
      ))
    }
    
    // Add new alerts
    for (const alert of newAlerts) {
      await this.addAlert(alert)
    }
  }

  private createAlert(
    type: Alert['type'],
    category: Alert['category'],
    title: string,
    message: string,
    threshold: number,
    actualValue: number
  ): Alert {
    return {
      id: `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
      type,
      category,
      title,
      message,
      threshold,
      actualValue,
      timestamp: new Date(),
      resolved: false
    }
  }

  private async addAlert(alert: Alert): Promise<void> {
    // Check if similar alert already exists and is not resolved
    const existingAlert = this.alerts.find(a => 
      !a.resolved && 
      a.category === alert.category && 
      a.title === alert.title &&
      Date.now() - a.timestamp.getTime() < 300000 // Within 5 minutes
    )
    
    if (!existingAlert) {
      this.alerts.push(alert)
      this.emit('alert', alert)
      
      if (this.config.notifications.enabled) {
        await this.sendAlert(alert)
      }
    }
  }

  private async sendAlert(alert: Alert): Promise<void> {
    try {
      // Console notification
      if (this.config.notifications.channels.includes('console')) {
        const color = alert.type === 'CRITICAL' ? '\x1b[31m' : alert.type === 'WARNING' ? '\x1b[33m' : '\x1b[36m'
        console.log(`${color}[ALERT ${alert.type}] ${alert.title}: ${alert.message}\x1b[0m`)
      }
      
      // Database notification (could be expanded to external systems)
      if (this.config.notifications.channels.includes('database')) {
        // Could store alerts in database for dashboard
      }
    } catch (error) {
      console.error('[Monitoring] Failed to send alert:', error)
    }
  }

  // ============================================================================
  // API TRACKING
  // ============================================================================

  trackApiRequest(endpoint: string, responseTime: number, isError: boolean = false): void {
    if (!this.requestStats.has(endpoint)) {
      this.requestStats.set(endpoint, { times: [], errors: 0 })
    }
    
    const stats = this.requestStats.get(endpoint)!
    stats.times.push(Date.now())
    if (isError) stats.errors++
    
    // Keep only last 1000 requests per endpoint
    if (stats.times.length > 1000) {
      stats.times = stats.times.slice(-1000)
    }
  }

  // ============================================================================
  // DATA MANAGEMENT
  // ============================================================================

  private addMetrics(metrics: SystemMetrics): void {
    this.metrics.push(metrics)
    
    // Cleanup old metrics based on retention policy
    const retentionMs = this.config.sampling.retention * 60 * 60 * 1000
    const cutoff = Date.now() - retentionMs
    this.metrics = this.metrics.filter(m => m.timestamp.getTime() > cutoff)
  }

  getLatestMetrics(): SystemMetrics | null {
    return this.metrics.length > 0 ? this.metrics[this.metrics.length - 1] : null
  }

  getMetricsHistory(hours: number = 1): SystemMetrics[] {
    const cutoff = Date.now() - (hours * 60 * 60 * 1000)
    return this.metrics.filter(m => m.timestamp.getTime() > cutoff)
  }

  getActiveAlerts(): Alert[] {
    return this.alerts.filter(a => !a.resolved)
  }

  getAllAlerts(limit: number = 100): Alert[] {
    return this.alerts.slice(-limit).reverse()
  }

  async resolveAlert(alertId: string): Promise<boolean> {
    const alert = this.alerts.find(a => a.id === alertId)
    if (alert && !alert.resolved) {
      alert.resolved = true
      alert.resolvedAt = new Date()
      this.emit('alertResolved', alert)
      return true
    }
    return false
  }

  // ============================================================================
  // LIFECYCLE MANAGEMENT
  // ============================================================================

  start(): void {
    if (this.intervalId) {
      this.stop()
    }
    
    this.intervalId = setInterval(async () => {
      try {
        await this.collectSystemMetrics()
      } catch (error) {
        console.error('[Monitoring] Error collecting metrics:', error)
      }
    }, this.config.sampling.interval)
    
    console.log(`[Monitoring] Started with ${this.config.sampling.interval}ms interval`)
  }

  stop(): void {
    if (this.intervalId) {
      clearInterval(this.intervalId)
      this.intervalId = null
      console.log('[Monitoring] Stopped')
    }
  }

  // ============================================================================
  // PERFORMANCE RECOMMENDATIONS
  // ============================================================================

  generateOptimizationRecommendations(): Array<{
    category: string
    priority: 'HIGH' | 'MEDIUM' | 'LOW'
    title: string
    description: string
    impact: string
    implementation: string
  }> {
    const recommendations = []
    const latest = this.getLatestMetrics()
    if (!latest) return recommendations
    
    // CPU recommendations
    if (latest.cpu.usage > 70) {
      recommendations.push({
        category: 'Performance',
        priority: 'HIGH' as const,
        title: 'Optimize CPU Usage',
        description: `CPU usage is at ${latest.cpu.usage}%, which may impact response times`,
        impact: 'Improved response times and system stability',
        implementation: 'Review data collection schedules, implement caching, optimize database queries'
      })
    }
    
    // Memory recommendations
    if (latest.memory.systemMemory.utilization > 80) {
      recommendations.push({
        category: 'Performance',
        priority: 'HIGH' as const,
        title: 'Reduce Memory Usage',
        description: `Memory utilization is at ${latest.memory.systemMemory.utilization}%`,
        impact: 'Prevent out-of-memory errors and improve stability',
        implementation: 'Implement memory pooling, optimize data structures, add memory cleanup routines'
      })
    }
    
    // Database recommendations
    if (latest.database.responseTime > 1000) {
      recommendations.push({
        category: 'Database',
        priority: 'MEDIUM' as const,
        title: 'Optimize Database Performance',
        description: `Database response time is ${latest.database.responseTime}ms`,
        impact: 'Faster API responses and better user experience',
        implementation: 'Add database indexes, optimize queries, implement connection pooling'
      })
    }
    
    // API recommendations
    if (latest.api.errorRate > 2) {
      recommendations.push({
        category: 'API',
        priority: 'HIGH' as const,
        title: 'Reduce API Error Rate',
        description: `API error rate is ${latest.api.errorRate}%`,
        impact: 'Improved reliability and user satisfaction',
        implementation: 'Add better error handling, implement retry logic, improve input validation'
      })
    }
    
    // GC recommendations
    if (latest.gc.gcTime.percentage > 5) {
      recommendations.push({
        category: 'Performance',
        priority: 'MEDIUM' as const,
        title: 'Optimize Garbage Collection',
        description: `GC is consuming ${latest.gc.gcTime.percentage}% of runtime`,
        impact: 'Reduced pause times and better performance',
        implementation: 'Optimize object lifecycle, reduce temporary object creation, tune GC parameters'
      })
    }
    
    return recommendations.sort((a, b) => {
      const priorityOrder = { HIGH: 3, MEDIUM: 2, LOW: 1 }
      return priorityOrder[b.priority] - priorityOrder[a.priority]
    })
  }
}

export default MonitoringService.getInstance()